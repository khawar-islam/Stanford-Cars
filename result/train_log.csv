Epoch, lr, Train_Loss, Train_Acc, Test_Acc
===== Using Torch AMP =====
0, 0.0250, 5.3671, 0.890%, 0.982%
1, 0.0250, 5.1926, 1.274%, 1.679%
2, 0.0250, 5.0927, 1.719%, 2.350%
3, 0.0250, 4.9808, 2.750%, 2.599%
4, 0.0249, 4.7740, 4.089%, 4.253%
5, 0.0249, 4.2967, 7.199%, 4.688%
6, 0.0249, 3.6060, 14.854%, 11.329%
7, 0.0248, 2.7670, 28.742%, 13.220%
8, 0.0248, 1.9435, 46.872%, 26.688%
9, 0.0247, 1.3517, 61.699%, 43.005%
10, 0.0246, 0.9612, 72.062%, 42.942%
11, 0.0245, 0.6798, 80.188%, 40.779%
12, 0.0245, 0.4985, 85.735%, 52.195%
13, 0.0244, 0.3862, 89.020%, 64.308%
14, 0.0243, 0.2888, 92.273%, 63.313%
15, 0.0242, 0.2360, 94.115%, 59.396%
16, 0.0240, 0.1981, 95.285%, 65.800%
17, 0.0239, 0.1545, 96.645%, 71.111%
18, 0.0238, 0.1420, 97.185%, 72.379%
19, 0.0237, 0.1187, 97.719%, 68.325%
20, 0.0235, 0.1081, 98.164%, 69.954%
21, 0.0234, 0.1109, 98.078%, 62.293%
22, 0.0232, 0.1232, 97.903%, 64.470%
23, 0.0231, 0.0960, 98.508%, 74.356%
24, 0.0229, 0.1055, 98.250%, 66.397%
25, 0.0227, 0.1604, 97.084%, 63.201%
26, 0.0225, 0.1103, 98.155%, 77.316%
27, 0.0224, 0.0613, 99.165%, 78.983%
28, 0.0222, 0.0480, 99.408%, 80.798%
29, 0.0220, 0.0342, 99.619%, 78.025%
30, 0.0218, 0.0284, 99.745%, 84.305%
31, 0.0216, 0.0288, 99.751%, 79.990%
32, 0.0213, 0.3356, 93.093%, 52.755%
33, 0.0211, 0.2670, 94.198%, 72.839%
34, 0.0209, 0.1115, 98.008%, 73.038%
35, 0.0207, 0.0661, 99.015%, 81.370%
36, 0.0204, 0.0383, 99.570%, 85.574%
37, 0.0202, 0.0272, 99.687%, 86.631%
38, 0.0199, 0.0236, 99.739%, 86.034%
39, 0.0197, 0.0230, 99.791%, 86.333%
40, 0.0194, 0.0323, 99.690%, 78.299%
41, 0.0192, 0.2478, 95.678%, 54.856%
42, 0.0189, 0.2346, 95.644%, 69.556%
43, 0.0187, 0.0803, 98.766%, 79.754%
44, 0.0184, 0.0438, 99.408%, 85.400%
45, 0.0181, 0.0315, 99.632%, 87.402%
46, 0.0178, 0.0201, 99.754%, 87.303%
47, 0.0176, 0.0166, 99.822%, 88.845%
48, 0.0173, 0.0156, 99.859%, 88.347%
49, 0.0170, 0.0157, 99.847%, 88.994%
50, 0.0167, 0.0239, 99.804%, 84.840%
51, 0.0164, 0.1207, 98.619%, 54.819%
52, 0.0161, 0.3308, 93.836%, 66.198%
53, 0.0158, 0.0716, 99.061%, 84.492%
54, 0.0155, 0.0321, 99.592%, 86.867%
55, 0.0152, 0.0179, 99.779%, 86.109%
56, 0.0149, 0.0167, 99.807%, 87.278%
57, 0.0146, 0.0156, 99.828%, 88.633%
58, 0.0143, 0.0135, 99.896%, 89.703%
59, 0.0140, 0.0179, 99.819%, 88.049%
60, 0.0137, 0.0161, 99.899%, 89.392%
61, 0.0134, 0.0169, 99.856%, 89.591%
62, 0.0131, 0.0198, 99.837%, 88.795%
63, 0.0128, 0.1857, 97.621%, 64.171%
64, 0.0125, 0.1656, 97.553%, 78.386%
65, 0.0122, 0.0527, 99.337%, 85.947%
66, 0.0119, 0.0225, 99.715%, 86.333%
67, 0.0116, 0.0155, 99.831%, 89.541%
68, 0.0113, 0.0157, 99.816%, 88.161%
69, 0.0110, 0.0111, 99.902%, 90.437%
70, 0.0107, 0.0117, 99.865%, 90.113%
71, 0.0104, 0.0130, 99.871%, 89.093%
72, 0.0101, 0.0121, 99.920%, 90.548%
73, 0.0098, 0.0123, 99.908%, 90.138%
74, 0.0095, 0.0125, 99.911%, 90.163%
75, 0.0092, 0.0139, 99.902%, 90.163%
76, 0.0089, 0.0128, 99.923%, 90.486%
77, 0.0086, 0.0160, 99.889%, 90.101%
78, 0.0083, 0.0159, 99.889%, 90.586%
79, 0.0080, 0.0260, 99.850%, 88.919%
80, 0.0077, 0.0204, 99.886%, 90.300%
81, 0.0074, 0.0158, 99.923%, 84.268%
82, 0.0072, 0.0141, 99.926%, 90.424%
83, 0.0069, 0.0131, 99.914%, 90.399%
84, 0.0066, 0.0124, 99.942%, 88.186%
85, 0.0063, 0.0178, 99.896%, 85.076%
86, 0.0061, 0.0151, 99.960%, 90.076%
87, 0.0058, 0.0177, 99.893%, 87.216%
88, 0.0056, 0.0239, 99.843%, 87.999%
89, 0.0053, 0.0114, 99.957%, 90.548%
90, 0.0051, 0.0103, 99.963%, 90.760%
91, 0.0048, 0.0104, 99.948%, 90.511%
92, 0.0046, 0.0104, 99.951%, 90.486%
93, 0.0043, 0.0124, 99.923%, 89.006%
94, 0.0041, 0.0112, 99.963%, 90.834%
95, 0.0039, 0.0099, 99.969%, 90.909%
96, 0.0037, 0.0103, 99.957%, 90.897%
97, 0.0034, 0.0091, 99.985%, 90.611%
98, 0.0032, 0.0101, 99.979%, 91.208%
99, 0.0030, 0.0092, 99.979%, 90.810%
100, 0.0028, 0.0090, 99.988%, 90.474%
101, 0.0026, 0.0092, 99.979%, 90.984%
102, 0.0025, 0.0091, 99.979%, 90.822%
103, 0.0023, 0.0091, 99.985%, 90.959%
104, 0.0021, 0.0087, 99.994%, 90.934%
105, 0.0019, 0.0090, 99.982%, 91.083%
106, 0.0018, 0.0085, 99.994%, 90.872%
107, 0.0016, 0.0084, 99.997%, 90.971%
108, 0.0015, 0.0086, 99.991%, 91.033%
109, 0.0013, 0.0086, 99.994%, 91.009%
110, 0.0012, 0.0084, 99.991%, 91.009%
111, 0.0011, 0.0085, 99.997%, 90.934%
112, 0.0010, 0.0084, 100.000%, 91.033%
113, 0.0008, 0.0082, 99.994%, 91.145%
114, 0.0007, 0.0084, 100.000%, 91.033%
115, 0.0006, 0.0082, 99.997%, 91.058%
116, 0.0005, 0.0083, 100.000%, 91.220%
117, 0.0005, 0.0082, 100.000%, 90.909%
118, 0.0004, 0.0083, 100.000%, 90.847%
119, 0.0003, 0.0082, 100.000%, 91.033%
120, 0.0002, 0.0083, 99.997%, 90.946%
121, 0.0002, 0.0082, 100.000%, 91.033%
122, 0.0001, 0.0083, 100.000%, 90.934%
123, 0.0001, 0.0082, 100.000%, 90.884%
124, 0.0001, 0.0082, 99.997%, 91.046%
125, 0.0000, 0.0082, 100.000%, 91.083%
126, 0.0000, 0.0082, 100.000%, 91.071%
127, 0.0000, 0.0081, 100.000%, 91.071%
===== TESTING =====
Dataset 3pts512	ACC:100.00
Dataset val	ACC:91.22
